{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ДЗ Урок 4. Семантическая сегментация.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2X7Aph1ugLob",
        "colab_type": "text"
      },
      "source": [
        "### Подключение инфраструктуры"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaeIYvZYe_3C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Подключение к Google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obBIp7NLgQhj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH = '/content/drive/My Drive/GU_NN/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Er7DJFudgTLB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import os\n",
        "sys.path.append(PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3_xEi5Ef-xD",
        "colab_type": "text"
      },
      "source": [
        "### Задание\n",
        "\n",
        "Обучить модель семантической сегментации (человек-vs-фон) на подмножестве датасета MS COCO\n",
        "Библиотеки: [Python, Tensorflow]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCi1OmXBgZNb",
        "colab_type": "text"
      },
      "source": [
        "### Библиотеки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-xi7ekggYdc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import skimage.io as io\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1rUvtc4n7A-",
        "colab_type": "code",
        "outputId": "c5ed941e-0a88-49d8-dc1c-456140c3de2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTKcH8J1oQuV",
        "colab_type": "text"
      },
      "source": [
        "### Константы"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xcoe20apoUfM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "RANDOM_STATE = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0wHuVkHoY5V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.random.set_seed(RANDOM_STATE)\n",
        "np.random.seed(RANDOM_STATE)\n",
        "tf.compat.v1.random.set_random_seed(RANDOM_STATE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whSA5UGijYw4",
        "colab_type": "text"
      },
      "source": [
        "### Загрузка датасета COCO и COCO API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6kG-tY2gZWK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if 0:\n",
        "    #!cd 'drive/My Drive/GU_NN/data'  && wget http://images.cocodataset.org/zips/train2017.zip \n",
        "    #!cd 'drive/My Drive/GU_NN/data'  && wget http://images.cocodataset.org/zips/val2017.zip \n",
        "    #!cd 'drive/My Drive/GU_NN/data'  && wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip \n",
        "\n",
        "    #!cd 'drive/My Drive/GU_NN/data'  && unzip -q train2017.zip\n",
        "    #!cd 'drive/My Drive/GU_NN/data'  && unzip -q val2017.zip\n",
        "    #!cd 'drive/My Drive/GU_NN/data'  && unzip -q annotations_trainval2017.zip\n",
        "\n",
        "    #!cd 'drive/My Drive/GU_NN/data' && git clone https://github.com/cocodataset/cocoapi\n",
        "    #!cd 'drive/My Drive/GU_NN/data/cocoapi/PythonAPI' && make\n",
        "    print('End')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzUr8t7liTSp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "COCO_ROOT = os.path.join(PATH,'data')\n",
        "import sys\n",
        "sys.path.insert(0, os.path.join(COCO_ROOT, 'cocoapi/PythonAPI'))\n",
        "from pycocotools.coco import COCO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMZD9WOjiZc_",
        "colab_type": "text"
      },
      "source": [
        "### Универсальный класс Dataset для сегментации"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAHtUUGIiXQf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dataset():\n",
        "\n",
        "    def crop_images(self, img, inp_size, random_crop=False):\n",
        "      \n",
        "        shape = tf.shape(img)\n",
        "        pad = (\n",
        "            [0, tf.maximum(inp_size - shape[0], 0)],\n",
        "            [0, tf.maximum(inp_size - shape[1], 0)],\n",
        "            [0, 0],\n",
        "        )\n",
        "        img = tf.pad(img, pad)\n",
        "        if random_crop:\n",
        "            #img = tf.image.random_crop(img, (inp_size, inp_size, shape[2]))\n",
        "            img = tf.image.random_crop(img, (inp_size, inp_size, 4)) \n",
        "        else: # central crop\n",
        "            shape = tf.shape(img)\n",
        "            ho = (shape[0] - inp_size) // 2\n",
        "            wo = (shape[1] - inp_size) // 2\n",
        "            #img = img[ho:ho+inp_size, wo:wo+inp_size, :]\n",
        "            img = img[ho:ho+inp_size, wo:wo+inp_size, :4]\n",
        "        return img\n",
        "\n",
        "    def train_dataset(self, batch_size, epochs, inp_size):\n",
        "\n",
        "        def item_to_images(item):\n",
        "            random_crop = True\n",
        "            img_combined = tf.py_function(self.read_images, [item], tf.uint8)\n",
        "            img_combined = self.crop_images(img_combined, inp_size, random_crop)\n",
        "            img = tf.cast(img_combined[...,:3], tf.float32) / np.float32(255.)\n",
        "            mask_class = tf.cast(img_combined[...,3:4], tf.float32)\n",
        "            return img, mask_class\n",
        "\n",
        "        dataset = tf.data.Dataset.from_tensor_slices(self.img_list)\n",
        "        dataset = dataset.shuffle(buffer_size=len(self.img_list))\n",
        "        dataset = dataset.map(item_to_images)\n",
        "        dataset = dataset.repeat(epochs)\n",
        "        dataset = dataset.batch(batch_size, drop_remainder=True)\n",
        "\n",
        "        return dataset\n",
        "\n",
        "    def val_dataset(self, batch_size, inp_size):\n",
        "\n",
        "        def item_to_images(item):\n",
        "            random_crop = False\n",
        "            img_combined = tf.py_function(self.read_images, [item], tf.uint8)\n",
        "            img_combined = self.crop_images(img_combined, inp_size, random_crop)\n",
        "\n",
        "            img = tf.cast(img_combined[...,:3], tf.float32) / np.float32(255.)\n",
        "            mask_class = tf.cast(img_combined[...,3:4], tf.float32)\n",
        "            return img, mask_class\n",
        "\n",
        "        dataset = tf.data.Dataset.from_tensor_slices(self.img_list)\n",
        "        dataset = dataset.map(item_to_images)\n",
        "        dataset = dataset.batch(batch_size, drop_remainder=True)\n",
        "\n",
        "        return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOWmt1jXih8o",
        "colab_type": "text"
      },
      "source": [
        "### Класс для сегментационного датасета COCO  \n",
        "Класс наследутся от универсльного Dataset и реализует кастомную функцию чтения данных."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GO3maffcwi9Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ujTX37gihfv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class COCO_Dataset(Dataset):\n",
        "\n",
        "    def __init__(self, sublist):\n",
        "        ann_file_fpath = os.path.join(COCO_ROOT, 'annotations', 'instances_'+sublist+'2017.json')\n",
        "        self.coco = COCO(ann_file_fpath)\n",
        "        self.sublist = sublist\n",
        "        self.cat_ids = self.coco.getCatIds(catNms=['person'])\n",
        "        self.img_list = self.coco.getImgIds(catIds=self.cat_ids)\n",
        "\n",
        "    def read_images(self, img_id):\n",
        "        img_id = int(img_id.numpy())\n",
        "        img_data = self.coco.loadImgs(img_id)[0]\n",
        "        img_fname = '/'.join(img_data['coco_url'].split('/')[-2:])\n",
        "\n",
        "        img = io.imread(os.path.join(COCO_ROOT, img_fname))\n",
        "        if len(img.shape) == 2:\n",
        "            img = np.tile(img[..., None], (1, 1, 3))\n",
        "\n",
        "        ann_ids = self.coco.getAnnIds(imgIds=img_data['id'], catIds=self.cat_ids, iscrowd=None)\n",
        "        anns = self.coco.loadAnns(ann_ids)\n",
        "        mask_class = np.zeros((img.shape[0], img.shape[1]), dtype=np.uint8)\n",
        "        for i in range(len(anns)):\n",
        "            mask_class += self.coco.annToMask(anns[i])\n",
        "        mask_class = (mask_class > 0).astype(np.uint8)\n",
        "        img_combined = np.concatenate([img, mask_class[..., None]], axis=2)\n",
        "        return img_combined\n",
        "\n",
        "    def build_csvperson(self):\n",
        "      with open(self.sublist+'person.csv', 'w', newline='') as csvfile:\n",
        "          fieldnames = ['id', 'file_name']\n",
        "          writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "          writer.writeheader()\n",
        "          for spam in self.coco.loadImgs(self.img_list):\n",
        "            writer.writerow({'id': spam['id'] , 'file_name': spam['file_name']})\n",
        "      print(f'{self.sublist}person.csv is ready')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoBoShAGjC5T",
        "colab_type": "code",
        "outputId": "6541806d-d8ea-44ac-d16b-4281505d8729",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "COCO_dataset_train = COCO_Dataset('train')\n",
        "COCO_dataset_val = COCO_Dataset('val')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=24.22s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=1.29s)\n",
            "creating index...\n",
            "index created!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTmz1S5HvJMM",
        "colab_type": "code",
        "outputId": "3b36d48e-ad21-4fe8-cd6c-859772f56eb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "COCO_dataset_val.build_csvperson()\n",
        "COCO_dataset_train.build_csvperson()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "valperson.csv is ready\n",
            "trainperson.csv is ready\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dtz1vHyejZRG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "IMG_INP_SIZE = 256\n",
        "EPOCHS = 1 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kfd-VUlFwQgl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ds = COCO_dataset_train.train_dataset(batch_size=BATCH_SIZE, epochs=EPOCHS, inp_size=IMG_INP_SIZE)\n",
        "val_ds = COCO_dataset_val.val_dataset(batch_size=BATCH_SIZE, inp_size=IMG_INP_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVW7Lam4wRFp",
        "colab_type": "text"
      },
      "source": [
        "### Модель"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E75h9k1mjf6v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ASPPBlock(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = tf.keras.layers.Conv2D(256, (1, 1), padding='same', activation='relu')\n",
        "        self.conv2 = tf.keras.layers.Conv2D(256, (3, 3), dilation_rate=6, padding='same', activation='relu')\n",
        "        self.conv3 = tf.keras.layers.Conv2D(256, (3, 3), dilation_rate=12, padding='same', activation='relu')\n",
        "        self.conv4 = tf.keras.layers.Conv2D(256, (3, 3), dilation_rate=18, padding='same', activation='relu')\n",
        "        self.conv5 = tf.keras.layers.Conv2D(256, (1, 1), padding='same', activation='relu')\n",
        "\n",
        "    def call(self, inp, is_training=False):\n",
        "        out1 = self.conv1(inp)\n",
        "        out2 = self.conv2(inp)\n",
        "        out3 = self.conv3(inp)\n",
        "        out4 = self.conv4(inp)\n",
        "        out = tf.concat([out1, out2, out3, out4], axis=3)\n",
        "        out = self.conv5(out)\n",
        "        return out\n",
        "    \n",
        "class ASPPNet(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu')\n",
        "        self.conv2 = tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu')\n",
        "        self.conv3 = tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu')\n",
        "        self.conv4 = tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu')\n",
        "        self.conv5 = tf.keras.layers.Conv2D(256, (3, 3), padding='same', activation='relu')\n",
        "        self.conv6 = tf.keras.layers.Conv2D(256, (3, 3), padding='same', activation='relu')\n",
        "        self.conv7 = tf.keras.layers.Conv2D(512, (3, 3), padding='same', activation='relu')\n",
        "        self.conv8 = tf.keras.layers.Conv2D(512, (3, 3), padding='same', activation='relu')\n",
        "        self.conv9 = tf.keras.layers.Conv2D(512, (3, 3), padding='same', activation='relu')\n",
        "        self.conv10 = tf.keras.layers.Conv2D(512, (3, 3), padding='same', activation='relu')\n",
        "\n",
        "        self.conv11 = tf.keras.layers.Conv2D(48, (1, 1), padding='same', activation='relu')\n",
        "        self.conv12 = tf.keras.layers.Conv2D(256, (3, 3), padding='same', activation='relu')\n",
        "        self.conv13 = tf.keras.layers.Conv2D(256, (3, 3), padding='same', activation='relu')\n",
        "        self.conv14 = tf.keras.layers.Conv2D(1, (1, 1), padding='same', activation=None)\n",
        "\n",
        "        self.maxpool = tf.keras.layers.MaxPooling2D((2, 2), (2, 2), padding='same')\n",
        "\n",
        "        self.aspp = ASPPBlock()\n",
        "\n",
        "    def call(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.conv2(out)\n",
        "        out = self.maxpool(out)\n",
        "        out = self.conv3(out)\n",
        "        out = self.conv4(out)\n",
        "        out = self.maxpool(out)\n",
        "        out = self.conv5(out)\n",
        "        out = self.conv6(out)\n",
        "        out_enc_mid = out\n",
        "        out = self.maxpool(out)\n",
        "        out = self.conv7(out)\n",
        "        out = self.conv8(out)\n",
        "        out = self.maxpool(out)\n",
        "        out = self.conv9(out)\n",
        "        out = self.conv10(out)\n",
        "\n",
        "        out = self.aspp(out)\n",
        "\n",
        "        out = tf.image.resize(out, tf.shape(out_enc_mid)[1:3], tf.image.ResizeMethod.BILINEAR)\n",
        "\n",
        "        out_enc_mid = self.conv11(out_enc_mid)\n",
        "\n",
        "        out = tf.concat([out, out_enc_mid], axis=3)\n",
        "\n",
        "        out = self.conv12(out)\n",
        "        out = self.conv13(out)\n",
        "        out = self.conv14(out)\n",
        "\n",
        "        out = tf.image.resize(out, tf.shape(x)[1:3], tf.image.ResizeMethod.BILINEAR)\n",
        "        out = tf.nn.sigmoid(out)\n",
        "        return out\n",
        "    \n",
        "model = ASPPNet()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRl7LyJ-wiOA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = tf.keras.losses.BinaryCrossentropy()\n",
        "model.compile(optimizer=\"adam\", loss=loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJFan3W5wnY_",
        "colab_type": "text"
      },
      "source": [
        "### Обучение"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ymtpF1owqSQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Добавим эпоху в имя файла (uses `str.format`)\n",
        "checkpoint_path = os.path.join(PATH, \"training\") + \"/cp-{epoch:04d}.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Создадим коллбек сохраняющий веса модели каждые 5 эпох\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_path, \n",
        "    verbose=0, \n",
        "    save_weights_only=True,\n",
        "    save_freq=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Hk8dmrAx8iS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "  model.load_weights(latest)\n",
        "except:\n",
        "  model.save_weights(checkpoint_path.format(epoch=0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARhcrGxL20aV",
        "colab_type": "code",
        "outputId": "573e609b-7d36-46fc-ccfc-167497a86a88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_ds"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((32, 256, 256, 3), (32, 256, 256, 1)), types: (tf.float32, tf.float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I42z_Fuk3j8D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Визуализация изображений\n",
        "if 1:\n",
        "  i = next(iter(train_ds))\n",
        "  for idx in range(5):\n",
        "      sample = i[0][idx].numpy()\n",
        "      seg_map = plt.get_cmap('viridis')(i[1][idx].numpy().reshape(IMG_INP_SIZE,IMG_INP_SIZE))[..., :3]\n",
        "      plt.imshow(sample*0.5 + seg_map*0.5)\n",
        "      plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZ4QfIWaxhmx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Обучаем модель с новым коллбеком\n",
        "%%time\n",
        "if 1:\n",
        "  history = model.fit(train_ds,  \n",
        "            epochs=EPOCHS,\n",
        "            steps_per_epoch=len(COCO_dataset_train.img_list)//BATCH_SIZE,\n",
        "            validation_data=val_ds,\n",
        "            callbacks=[cp_callback])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIoxF83uq-L7",
        "colab_type": "text"
      },
      "source": [
        "### Результат"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ft7mvw3WrIYE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Визуализация изображений\n",
        "if 1:\n",
        "  test_batch = next(iter(val_ds))\n",
        "  prediction = model.predict(test_batch)\n",
        "  for idx in range(5):\n",
        "      sample = test_batch[0][idx].numpy()\n",
        "      fig = plt.figure(figsize=(16,6))\n",
        "    \n",
        "      plt.subplot(1,2,1)\n",
        "      plt.title(\"True segment\")\n",
        "      val_seg_map = plt.get_cmap('viridis')(test_batch[1][idx].numpy().reshape(IMG_INP_SIZE,IMG_INP_SIZE))[..., :3]\n",
        "      plt.imshow(sample*0.5 + val_seg_map*0.5)\n",
        "\n",
        "      plt.subplot(1,2,2)\n",
        "      plt.title(\"Predict segment\")\n",
        "      pred_seg_map = plt.get_cmap('viridis')(prediction[idx].numpy().reshape(IMG_INP_SIZE,IMG_INP_SIZE))[..., :3]\n",
        "      plt.imshow(sample*0.5 + pred_seg_map *0.5)\n",
        "      plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}